<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Training and Evaluating Models &mdash; Student Intervention System 2016.03.11 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootswatch-3.3.4/spacelab/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2016.03.11',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Student Intervention System 2016.03.11 documentation" href="index.html" />
    <link rel="next" title="Choosing the Best Model" href="choosing_best_model.html" />
    <link rel="prev" title="Preparing the Data" href="preparing_data.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Student Intervention System</a>
        <span class="navbar-text navbar-version pull-left"><b>2016.03.11</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="classification_vs_regression.html">Classification vs Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="exploring_data.html">Exploring the Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparing_data.html">Preparing the Data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Training and Evaluating Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="choosing_best_model.html">Choosing the Best Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="citations.html">Citations</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Training and Evaluating Models</a><ul>
<li><a class="reference internal" href="#logistic-regression">Logistic Regression</a></li>
<li><a class="reference internal" href="#random-forests">Random Forests</a></li>
<li><a class="reference internal" href="#k-nearest-neighbors">K-Nearest Neighbors</a></li>
<li><a class="reference internal" href="#performance-comparisons">Performance Comparisons</a><ul>
<li><a class="reference internal" href="#summation">Summation</a><ul>
<li><a class="reference internal" href="#training-times">Training Times</a></li>
<li><a class="reference internal" href="#prediction-times">Prediction Times</a></li>
<li><a class="reference internal" href="#f1-prediction-scores-test-set">F1 Prediction Scores (Test Set)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#f1-scores">F1 Scores</a><ul>
<li><a class="reference internal" href="#training-set">Training Set</a></li>
<li><a class="reference internal" href="#test-set">Test Set</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparing-test-vs-train-scores-by-model">Comparing Test vs Train Scores by Model</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="preparing_data.html" title="Previous Chapter: Preparing the Data"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Preparing the...</span>
    </a>
  </li>
  <li>
    <a href="choosing_best_model.html" title="Next Chapter: Choosing the Best Model"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Choosing the ... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/training_and_evaluating.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="training-and-evaluating-models">
<h1>Training and Evaluating Models<a class="headerlink" href="#training-and-evaluating-models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="logistic-regression">
<h2>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h2>
<p>The first model I chose was <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression">Logistic Regression</a>. Logistic regression is a linear classification model that is useful when the target variable is categorical and the feature variables are either numeric or categorical (Peng C., et al, 2002), although the categorical variables have to be converted to numeric values prior to use. Logistic Regression has the advantage of being computationally cheap, reasonable to implement, and is interpretable but has the disadvantage that it is prone to underfitting (Harrington, 2012).</p>
<p>I chose this model for thre primary reasons:</p>
<blockquote>
<div><ul class="simple">
<li>Its coefficients are interpretable so besides predicting whether a student is at risk, factors that are most influential in determining students who are at risk can be identified</li>
<li>It suports ridge regression, including lasso regression which might help reduce the number of variables in the data set, both to aid interpretation and improve performance</li>
<li>It is well understood/well studied</li>
</ul>
</div></blockquote>
<p>Since it is a linear model it performs best when the data is linearly separable, which makes it a complement to Random Forests, the next model I chose.</p>
</div>
<div class="section" id="random-forests">
<h2>Random Forests<a class="headerlink" href="#random-forests" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier">Random Forests</a> are ensemble learners that combine predictions from multiple decision trees.</p>
<p>Decision Trees have several advantages including:</p>
<blockquote>
<div><ul class="simple">
<li>they are interpretable</li>
<li>they can sometimes fit complex data more easily than linear models</li>
<li>they don&#8217;t require dummy variables.</li>
</ul>
</div></blockquote>
<p>They are, however, generally not as accurate (James G. et al., 2013). Random Forests overcome the failings of the individual Decision Trees using two methods:</p>
<blockquote>
<div><ul class="simple">
<li>training each tree on a separate data set that is created by re-sampling with replacement from the original training set ( <em>bagging</em>) which improves the accuracy of the forest over that of an individual tree.</li>
<li>each tree in the forest uses a random sub-set of the features when deciding on a split so that there is sufficient diversity in the forest to improve reliability</li>
</ul>
</div></blockquote>
<p>The predicted output for the features is created by taking an average of the predictions given by the trees.</p>
<p>Random forests, like decision trees, can be used for either classification or regression, but the trade-off for their improved accuracy is that the ensemble is not as directly interpretable as the individual decision trees are. Decision Trees, and thus Random Forests, don&#8217;t assume linear separability and can perform better than linear models when the data isn&#8217;t linearly separable, but may not do as well in the cases where the linear model is appropriate (James G. et al., 2013), thus, given the number of variables I thought that it might be more effective on this data set in the event that Logistic Regression cannot model the data well.</p>
</div>
<div class="section" id="k-nearest-neighbors">
<h2>K-Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permalink to this headline">¶</a></h2>
<p>My final predictor used <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">K-Nearest Neighbors (KNN)</a> classification. It is a fairly straight-forward method that doesn&#8217;t build a model in the sense that the other two methods do. Instead KNN stores the training data and when asked to make a prediction finds the <em>k</em> number of points in the training data that are &#8216;closest&#8217; to the input and calculates then
probability of a classification (say <em>y=1</em>) as the fraction of the k-neighbors that are of that class. Thus if k=4 and three of the chosen neighbors are classified as <em>1</em> then the predicted class will be <em>1</em>, because the majority of the neighbors were 1.</p>
<p>Because <em>KNN</em> doesn&#8217;t build a model the way the other two classifiers do, it has the quickest training time but trades this for the longest prediction times.</p>
<p>Unlike Logistic Regression, KNN doesn&#8217;t require linear separability and unlike some other methods also makes no assumption about the distribution of the data (it is <em>non-parametric</em>). This makes KNN more flexible, but how accurate it is depends on the choice of <em>k</em>. If <em>k</em> is too small it will tend to overfit the training data and if <em>k</em> is too large, it will become too rigid. Besides the difficulty in choosing <em>k</em>, because it is non-parametric it&#8217;s not possible to inspect the model to decide which features are important and it needs more data to be accurate (James G., et al., 2013).</p>
<p>I thought that KNN might be a good non-parametric alternative to Logistic Regression since the data comes from students attending two schools in Portugal which might make the instances more similar than dissimilar, the &#8216;nearest neighbor&#8217; method was conceptually appropriate and it is different enough in approach that it might improve on the other two methods should the separation of the classes be unusually difficult.</p>
</div>
<div class="section" id="performance-comparisons">
<h2>Performance Comparisons<a class="headerlink" href="#performance-comparisons" title="Permalink to this headline">¶</a></h2>
<p>To compare the models each was fit using their default parameters on the same sub-sets of the data. The sub-sets were made of the first 100, 200, and 300 observations of the data. Times are in seconds and the &#8216;best&#8217; scores are based on their F1 scores, the weighted average of their prediction and recall scores.</p>
<p>Since the running times are based on my machine&#8217;s performance as much as that of the classifiers&#8217; all times are the minimum value from 100 repetitions (following the advice in the python <a class="reference external" href="https://docs.python.org/2/library/timeit.html">timeit</a> documentation). The f1-scores are the median values for the 100 repetitions.</p>
<table border="1" class="docutils" id="id3">
<caption><span class="caption-text">LogisticRegression</span><a class="headerlink" href="#id3" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Size</th>
<th class="head">Time (train)</th>
<th class="head">Time (predict)</th>
<th class="head">Train F1</th>
<th class="head">Test F1</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100</td>
<td>0.0011</td>
<td>0.0001</td>
<td>0.8702</td>
<td>0.6720</td>
</tr>
<tr class="row-odd"><td>200</td>
<td>0.0025</td>
<td>0.0001</td>
<td>0.8333</td>
<td>0.7910</td>
</tr>
<tr class="row-even"><td>300</td>
<td>0.0029</td>
<td>0.0001</td>
<td>0.8075</td>
<td>0.8120</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Best score and size of data-set that gave the best test score:</dt>
<dd><ul class="first last simple">
<li>best score: 0.81</li>
<li>best size: 300</li>
</ul>
</dd>
</dl>
<table border="1" class="docutils" id="id4">
<caption><span class="caption-text">RandomForestClassifier</span><a class="headerlink" href="#id4" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Size</th>
<th class="head">Time (train)</th>
<th class="head">Time (predict)</th>
<th class="head">Train F1</th>
<th class="head">Test F1</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100</td>
<td>0.0198</td>
<td>0.0011</td>
<td>0.9841</td>
<td>0.6557</td>
</tr>
<tr class="row-odd"><td>200</td>
<td>0.0208</td>
<td>0.0011</td>
<td>0.9887</td>
<td>0.7087</td>
</tr>
<tr class="row-even"><td>300</td>
<td>0.0218</td>
<td>0.0012</td>
<td>0.9949</td>
<td>0.7714</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Best score and size of data-set that gave the best test score:</dt>
<dd><ul class="first last simple">
<li>best score: 0.77</li>
<li>best size: 300</li>
</ul>
</dd>
</dl>
<table border="1" class="docutils" id="id5">
<caption><span class="caption-text">KNeighborsClassifier</span><a class="headerlink" href="#id5" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Size</th>
<th class="head">Time (train)</th>
<th class="head">Time (predict)</th>
<th class="head">Train F1</th>
<th class="head">Test F1</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100</td>
<td>0.0004</td>
<td>0.0013</td>
<td>0.8244</td>
<td>0.7519</td>
</tr>
<tr class="row-odd"><td>200</td>
<td>0.0005</td>
<td>0.0019</td>
<td>0.8099</td>
<td>0.7536</td>
</tr>
<tr class="row-even"><td>300</td>
<td>0.0006</td>
<td>0.0027</td>
<td>0.8491</td>
<td>0.7945</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Best score and size of data-set that gave the best test score:</dt>
<dd><ul class="first last simple">
<li>best score: 0.79</li>
<li>best size: 300</li>
</ul>
</dd>
</dl>
<div class="section" id="summation">
<h3>Summation<a class="headerlink" href="#summation" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="9%" />
<col width="20%" />
<col width="20%" />
<col width="22%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Classifier</th>
<th class="head">Score</th>
<th class="head">Training-Size</th>
<th class="head">Training-Time</th>
<th class="head">Prediction-Time</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>LogisticRegression</td>
<td>0.81</td>
<td>300</td>
<td>0.0029</td>
<td>0.0001</td>
</tr>
<tr class="row-odd"><td>KNeighborsClassifier</td>
<td>0.79</td>
<td>300</td>
<td>0.0006</td>
<td>0.0027</td>
</tr>
<tr class="row-even"><td>RandomForestClassifier</td>
<td>0.77</td>
<td>300</td>
<td>0.0218</td>
<td>0.0012</td>
</tr>
</tbody>
</table>
<p>It looks like all three did about equally well on the test-sets.</p>
<p>As expected, KNN had the shortest training time and the longest prediction time. Since the values are so small, I&#8217;ll look at the ratios of the times next instead of the absolute times.</p>
<div class="section" id="training-times">
<h4>Training Times<a class="headerlink" href="#training-times" title="Permalink to this headline">¶</a></h4>
<table border="1" class="docutils">
<colgroup>
<col width="86%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Classifiers</th>
<th class="head">Ratio</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>LogisticRegression/KNeighborsClassifier</td>
<td>4.45</td>
</tr>
<tr class="row-odd"><td>RandomForestClassifier/KNeighborsClassifier</td>
<td>33.75</td>
</tr>
<tr class="row-even"><td>RandomForestClassifier/LogisticRegression</td>
<td>7.59</td>
</tr>
</tbody>
</table>
<p>The Random Forest classifier was 5-10 times slower than the Logistic Regression classifier, which was itself about 5 times slower than the KNN classifier when training the models.</p>
</div>
<div class="section" id="prediction-times">
<h4>Prediction Times<a class="headerlink" href="#prediction-times" title="Permalink to this headline">¶</a></h4>
<table border="1" class="docutils">
<colgroup>
<col width="86%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Classifiers</th>
<th class="head">Ratio</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>KNeighborsClassifier/LogisticRegression</td>
<td>20.23</td>
</tr>
<tr class="row-odd"><td>KNeighborsClassifier/RandomForestClassifier</td>
<td>2.29</td>
</tr>
<tr class="row-even"><td>RandomForestClassifier/LogisticRegression</td>
<td>8.84</td>
</tr>
</tbody>
</table>
<p>It looks like the Logistic Regression classifier was significantly faster than either the Random Forest classifier or the K-Nearest Neighbors classifier - about 20 times faster than KNN and 5-10 times faster than the Random Forest classifier.</p>
</div>
<div class="section" id="f1-prediction-scores-test-set">
<h4>F1 Prediction Scores (Test Set)<a class="headerlink" href="#f1-prediction-scores-test-set" title="Permalink to this headline">¶</a></h4>
<table border="1" class="docutils">
<colgroup>
<col width="86%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Classifiers</th>
<th class="head">Ratio</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>LogisticRegression/KNeighborsClassifier</td>
<td>1.02</td>
</tr>
<tr class="row-odd"><td>KNeighborsClassifier/RandomForestClassifier</td>
<td>1.03</td>
</tr>
<tr class="row-even"><td>LogisticRegression/RandomForestClassifier</td>
<td>1.05</td>
</tr>
</tbody>
</table>
<p>The three models seem to have been comparable once the training data reached 300 instances.</p>
</div>
</div>
</div>
<div class="section" id="f1-scores">
<h2>F1 Scores<a class="headerlink" href="#f1-scores" title="Permalink to this headline">¶</a></h2>
<p>Although I printed the tables for the F1 scores I will plot them here to take a closer look at them. The training-set sizes for the plots ranged from 10 to 300, increasing in steps of 10.</p>
<div class="section" id="training-set">
<h3>Training Set<a class="headerlink" href="#training-set" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/f1_scores_training.svg"><div align="center" class="align-center"><img src="_images/f1_scores_training.svg" /></div>
</a>
<p>The Random Forest did well on the training set from the start, while the K-nearest Neighbor classifier  and the Logistic Regression classifier were erratic until just over 100 training instances. Neither K-Nearest Neighbors nor Logistic Regression was able to do as well on the training set as Random Forests did, suggesting that they are underfitting the data.</p>
</div>
<div class="section" id="test-set">
<h3>Test Set<a class="headerlink" href="#test-set" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="_images/f1_scores_test.svg"><div align="center" class="align-center"><img src="_images/f1_scores_test.svg" /></div>
</a>
<p>All three classifiers did comparably once the training set was increased to 300 instances, but the Random Forest Classifier shows larger fluctuations in the F1 score than the other classifiers, while the Logistic Regression classifier seemed to be the most stable, and performed the best for most of the instance-counts.</p>
</div>
</div>
<div class="section" id="comparing-test-vs-train-scores-by-model">
<h2>Comparing Test vs Train Scores by Model<a class="headerlink" href="#comparing-test-vs-train-scores-by-model" title="Permalink to this headline">¶</a></h2>
<a class="reference internal image-reference" href="_images/f1_scores_LogisticRegression.svg"><div align="center" class="align-center"><img src="_images/f1_scores_LogisticRegression.svg" /></div>
</a>
<p>The training and testing sets for the Logistic Regression seem to be converging around 0.8, suggesting the model is underfitting and may not be complex enough for the data. Oddly, the test score is better than  the training score after about 250 training instances. Looking at the table above, the differences are fractional and might just be that the larger training set has proportionally more difficult instances than the test-set.</p>
<a class="reference internal image-reference" href="_images/f1_scores_KNeighborsClassifier.svg"><div align="center" class="align-center"><img src="_images/f1_scores_KNeighborsClassifier.svg" /></div>
</a>
<p>The K-Nearest Neighbors classifier seems to perform comparably to the Logistic Regression classifier, although the two curves haven&#8217;t converged yet, suggesting that it might be improved with more data, although it will still underfit the data.</p>
<a class="reference internal image-reference" href="_images/f1_scores_RandomForestClassifier.svg"><div align="center" class="align-center"><img src="_images/f1_scores_RandomForestClassifier.svg" /></div>
</a>
<p>The Random Forest classifier doesn&#8217;t do better with the test data than the other two classifiers but is much better with the training data, suggesting that it is currently overfitting, and might be improved with more data.</p>
</div>
</div>


    </div>
      
  </div>
</div>


<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016, Russell Nakamura.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.<br/>
    </p>
  </div>
</footer>

  </body>
</html>